{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d392347f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "cwd = Path.cwd()\n",
    "if cwd.name == \"notebooks\":\n",
    "    os.chdir(cwd.parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c8dd997",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-01-18 15:53:28.598\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mkimia_infer.api.kimia\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m16\u001b[0m - \u001b[1mLoading kimi-audio main model\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec01f7bdacb142f593f2a83a14e681f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 64 files:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dec0601685104d898b77c6cae9bf523b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.yaml: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3704f249807b4bb980fca3e04f3131d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e572c6bac970427c9e3875befff05725",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "configuration_moonshot_kimia.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f86cae2b474047b191b521a671c7f96b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/24.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26b500f5087346af8b716f0badc502b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5f5482a427a45228dbe9a501b71f996",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       ".gitattributes: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2970159491f5450db9564a0805956e23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "audio_detokenizer/model.pt:   0%|          | 0.00/19.0G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d49056cb5d9f41e5a5e584cc65678436",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-1-of-35.safetensors:   0%|          | 0.00/466M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c26615a0739c4a66ae97a1c5c76ba9ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-10-of-35.safetensors:   0%|          | 0.00/466M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "563cc7fee6dc47b9961d3a36640bd3bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-12-of-35.safetensors:   0%|          | 0.00/466M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af316831d10b4dcdad231d895de8c94e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-11-of-35.safetensors:   0%|          | 0.00/466M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6edc1744a3d455eaec4d5f547dd8489",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-13-of-35.safetensors:   0%|          | 0.00/466M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6eec1f9105e249dcb46788ddf7e280db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-14-of-35.safetensors:   0%|          | 0.00/466M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61e11a965535408389b3da76fe3e07da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-15-of-35.safetensors:   0%|          | 0.00/466M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9f2115b96f7455581cda92de0a42f3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-16-of-35.safetensors:   0%|          | 0.00/466M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20fffa0bebd14f9fb53809792b54b95c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-17-of-35.safetensors:   0%|          | 0.00/466M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d932c1f1e3024935a6359300b6cff696",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-18-of-35.safetensors:   0%|          | 0.00/466M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f08dac259db7438fb25b9d2bf7ec7ff3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-19-of-35.safetensors:   0%|          | 0.00/466M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c353cb63142e468691a6da6099b47055",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-2-of-35.safetensors:   0%|          | 0.00/466M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e8625da9ffa485996bb9314cdd6e7ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-20-of-35.safetensors:   0%|          | 0.00/466M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b32a75ab80d64dac98f2ae9c02479688",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-21-of-35.safetensors:   0%|          | 0.00/466M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "121b3a7e8b4e4d5fa1578234842f6383",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-22-of-35.safetensors:   0%|          | 0.00/466M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44efe0e01df9427fbaf23c3b48e226d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-23-of-35.safetensors:   0%|          | 0.00/466M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec46e0e2ac214a1fb2bd1fceecdf84fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-24-of-35.safetensors:   0%|          | 0.00/466M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66086369d84743bb9b33f87d6a3f83ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-25-of-35.safetensors:   0%|          | 0.00/466M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ee2491c8f7946d59ab7a40430f5c3dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-26-of-35.safetensors:   0%|          | 0.00/466M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bfaa674bbe448aa9e985684b74f0990",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-27-of-35.safetensors:   0%|          | 0.00/466M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccff9401bc01492d9b68e63ee744ed89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-28-of-35.safetensors:   0%|          | 0.00/466M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff773dc60a38404f957061347ecec78a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-29-of-35.safetensors:   0%|          | 0.00/466M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22abc4bb95dc44b4abcb8739d001df95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-3-of-35.safetensors:   0%|          | 0.00/466M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44e5a4413d354bc5a6bd9f5688c56b91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-30-of-35.safetensors:   0%|          | 0.00/466M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32158c03c1f1456b8b6a30d6ec59df52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-31-of-35.safetensors:   0%|          | 0.00/466M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4c3a909045f485597daca8192a67d6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-32-of-35.safetensors:   0%|          | 0.00/466M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2f06c1bc0e3491cba564e1adf908555",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-33-of-35.safetensors:   0%|          | 0.00/466M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d60f2abab2ce402bafd778f5df624ae8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-34-of-35.safetensors:   0%|          | 0.00/466M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d09a6dc50589488db84cdf3afe37561f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-35-of-35.safetensors:   0%|          | 0.00/62.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6009f34471c942b89f9e9f268c43f564",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-36-of-36.safetensors:   0%|          | 0.00/3.62G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c901be14c9034a81865bbe11a06057b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-4-of-35.safetensors:   0%|          | 0.00/466M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc5a08b462e64f39a7b2b9cae928d44e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-5-of-35.safetensors:   0%|          | 0.00/466M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8eacdc386311477ebf3905233d2d06e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-6-of-35.safetensors:   0%|          | 0.00/466M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08e0a704ab7b420ebe485a4d0433aff2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-7-of-35.safetensors:   0%|          | 0.00/466M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e60bae562fca4f5288a80838648f0c2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-8-of-35.safetensors:   0%|          | 0.00/466M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1de822b67fec489a95230f2130aafab0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-9-of-35.safetensors:   0%|          | 0.00/466M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0604012cbd154cfbadc69dba0d113476",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebc6f4f1cef74a0785efea8901bff6e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modeling_moonshot_kimia.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bcbd72fbfcf497f8b72540ad1d34681",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed709a6d860549acbf149694f3384415",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tiktoken.model:   0%|          | 0.00/2.56M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53ee0cb4ad5e44c49e8a1f530db1ecf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenization_kimia.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96ccf70d223241d98fcd979dcccefc99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b348716cbba4d2c99bc642df00ec8e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "054250c5aae744c681c7d455c8cea50a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocoder/model.pt:   0%|          | 0.00/965M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74b0a67a8c5940e29a9248957c52d2cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39bf987998474b5b80259034ca0c6d0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "285732b5d75047c1928de2bdf28d9793",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8041058440524d5a9f1f0ff37dcd9810",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21aaba06369c45a4ba3fdb571d4149e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f5780479b9a4454a560c7d2762de979",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "whisper-large-v3/model.safetensors:   0%|          | 0.00/3.09G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e75fabd4ac94408eb280968a8eb4dd59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "normalizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9736d9e3a2954f86a0de19830100e973",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/340 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ef13c184a284b92800f894f465ced9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "002baf9862384d15b41b727a34aad212",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "306038073aec40c195a82a3ca968171f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fbcd33cb73a443fb7bc50b139c30bc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-01-18 15:58:59.614\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mkimia_infer.api.kimia\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m25\u001b[0m - \u001b[1mLooking for resources in /nfs/home/dasaro/.cache/huggingface/hub/models--moonshotai--Kimi-Audio-7B-Instruct/snapshots/9a82a84c37ad9eb1307fb6ed8d7b397862ef9e6b\u001b[0m\n",
      "\u001b[32m2026-01-18 15:58:59.615\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mkimia_infer.api.kimia\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m26\u001b[0m - \u001b[1mLoading whisper model\u001b[0m\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "using normal flash attention\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fa869f77f2049c28c46916afd2725a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6486b332513443a4a8e42d44100b1559",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1649edc8ac1f44b6b876aef04e416b8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.46G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf1704707b8148e0911850fc1fa81839",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/340 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-01-18 15:59:42.590\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mkimia_infer.api.prompt_manager\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1mLooking for resources in /nfs/home/dasaro/.cache/huggingface/hub/models--moonshotai--Kimi-Audio-7B-Instruct/snapshots/9a82a84c37ad9eb1307fb6ed8d7b397862ef9e6b\u001b[0m\n",
      "\u001b[32m2026-01-18 15:59:42.592\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mkimia_infer.api.prompt_manager\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mLoading whisper model\u001b[0m\n",
      "\u001b[32m2026-01-18 15:59:48.021\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mkimia_infer.api.prompt_manager\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mLoading text tokenizer\u001b[0m\n",
      "\u001b[32m2026-01-18 15:59:48.320\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mkimia_infer.api.kimia\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m41\u001b[0m - \u001b[1mLoading detokenizer\u001b[0m\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /nfs/home/dasaro/research/FairMLLM-Emotion-Recognition/.kimi_venv/lib/python3.10/site-packages/kimia_infer/models/detokenizer/vocoder/alias_free_activation/cuda/build/build.ninja...\n",
      "/nfs/home/dasaro/research/FairMLLM-Emotion-Recognition/.kimi_venv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
      "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
      "  warnings.warn(\n",
      "Building extension module anti_alias_activation_cuda...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/3] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output anti_alias_activation_cuda.cuda.o.d -DTORCH_EXTENSION_NAME=anti_alias_activation_cuda -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -isystem /nfs/home/dasaro/research/FairMLLM-Emotion-Recognition/.kimi_venv/lib/python3.10/site-packages/torch/include -isystem /nfs/home/dasaro/research/FairMLLM-Emotion-Recognition/.kimi_venv/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /nfs/home/dasaro/research/FairMLLM-Emotion-Recognition/.kimi_venv/lib/python3.10/site-packages/torch/include/TH -isystem /nfs/home/dasaro/research/FairMLLM-Emotion-Recognition/.kimi_venv/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /nfs/home/dasaro/.pyenv/versions/3.10.12/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 --compiler-options '-fPIC' -O3 -gencode arch=compute_70,code=sm_70 --use_fast_math -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda -gencode arch=compute_80,code=sm_80 -std=c++17 -c /nfs/home/dasaro/research/FairMLLM-Emotion-Recognition/.kimi_venv/lib/python3.10/site-packages/kimia_infer/models/detokenizer/vocoder/alias_free_activation/cuda/anti_alias_activation_cuda.cu -o anti_alias_activation_cuda.cuda.o \n",
      "\u001b[31mFAILED: [code=1] \u001b[0manti_alias_activation_cuda.cuda.o \n",
      "/usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output anti_alias_activation_cuda.cuda.o.d -DTORCH_EXTENSION_NAME=anti_alias_activation_cuda -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -isystem /nfs/home/dasaro/research/FairMLLM-Emotion-Recognition/.kimi_venv/lib/python3.10/site-packages/torch/include -isystem /nfs/home/dasaro/research/FairMLLM-Emotion-Recognition/.kimi_venv/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /nfs/home/dasaro/research/FairMLLM-Emotion-Recognition/.kimi_venv/lib/python3.10/site-packages/torch/include/TH -isystem /nfs/home/dasaro/research/FairMLLM-Emotion-Recognition/.kimi_venv/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /nfs/home/dasaro/.pyenv/versions/3.10.12/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 --compiler-options '-fPIC' -O3 -gencode arch=compute_70,code=sm_70 --use_fast_math -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda -gencode arch=compute_80,code=sm_80 -std=c++17 -c /nfs/home/dasaro/research/FairMLLM-Emotion-Recognition/.kimi_venv/lib/python3.10/site-packages/kimia_infer/models/detokenizer/vocoder/alias_free_activation/cuda/anti_alias_activation_cuda.cu -o anti_alias_activation_cuda.cuda.o \n",
      "In file included from /usr/local/cuda/include/cuda_runtime.h:83,\n",
      "                 from <command-line>:\n",
      "/usr/local/cuda/include/crt/host_config.h:132:2: error: #error -- unsupported GNU version! gcc versions later than 12 are not supported! The nvcc flag '-allow-unsupported-compiler' can be used to override this version check; however, using an unsupported host compiler may cause compilation failure or incorrect run time execution. Use at your own risk.\n",
      "  132 | #error -- unsupported GNU version! gcc versions later than 12 are not supported! The nvcc flag '-allow-unsupported-compiler' can be used to override this version check; however, using an unsupported host compiler may cause compilation failure or incorrect run time execution. Use at your own risk.\n",
      "      |  ^~~~~\n",
      "[2/3] c++ -MMD -MF anti_alias_activation.o.d -DTORCH_EXTENSION_NAME=anti_alias_activation_cuda -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -isystem /nfs/home/dasaro/research/FairMLLM-Emotion-Recognition/.kimi_venv/lib/python3.10/site-packages/torch/include -isystem /nfs/home/dasaro/research/FairMLLM-Emotion-Recognition/.kimi_venv/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /nfs/home/dasaro/research/FairMLLM-Emotion-Recognition/.kimi_venv/lib/python3.10/site-packages/torch/include/TH -isystem /nfs/home/dasaro/research/FairMLLM-Emotion-Recognition/.kimi_venv/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /nfs/home/dasaro/.pyenv/versions/3.10.12/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++17 -O3 -c /nfs/home/dasaro/research/FairMLLM-Emotion-Recognition/.kimi_venv/lib/python3.10/site-packages/kimia_infer/models/detokenizer/vocoder/alias_free_activation/cuda/anti_alias_activation.cpp -o anti_alias_activation.o \n",
      "ninja: build stopped: subcommand failed.\n",
      "Automatic loading from HF Hub might require specific setup.\n",
      "Refer to Kimi-Audio docs. Trying local path example (update path!). Error: Error building extension 'anti_alias_activation_cuda'\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 54\u001b[0m\n\u001b[1;32m     47\u001b[0m messages_asr \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     48\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessage_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease transcribe the following audio:\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m     49\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessage_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maudio\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: asr_audio_path}\n\u001b[1;32m     50\u001b[0m ]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# Generate only text output\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# Note: Ensure the model object and generate method accept device placement if needed\u001b[39;00m\n\u001b[0;32m---> 54\u001b[0m _, text_output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mgenerate(messages_asr, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msampling_params, output_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m>>> ASR Output Text: \u001b[39m\u001b[38;5;124m\"\u001b[39m, text_output)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# Expected output: \"这并不是告别，这是一个篇章的结束，也是新篇章的开始。\" (Example)\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "import soundfile as sf\n",
    "# Assuming the KimiAudio class is available after installation\n",
    "from kimia_infer.api.kimia import KimiAudio\n",
    "import torch # Ensure torch is imported if needed for device placement\n",
    "\n",
    "# --- 1. Load Model ---\n",
    "# Load the model from Hugging Face Hub\n",
    "# Make sure you are logged in (`huggingface-cli login`) if the repo is private.\n",
    "model_id = \"moonshotai/Kimi-Audio-7B-Instruct\" # Or \"Kimi/Kimi-Audio-7B\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\" # Example device placement\n",
    "# Note: The KimiAudio class might handle model loading differently.\n",
    "# You might need to pass the model_id directly or download checkpoints manually\n",
    "# and provide the local path as shown in the original readme_kimia.md.\n",
    "# Please refer to the main Kimi-Audio repository for precise loading instructions.\n",
    "# Example assuming KimiAudio takes the HF ID or a local path:\n",
    "try:\n",
    "    model = KimiAudio(model_path=model_id, load_detokenizer=True) # May need device argument\n",
    "    model.to(device) # Example device placement\n",
    "except Exception as e:\n",
    "    print(f\"Automatic loading from HF Hub might require specific setup.\")\n",
    "    print(f\"Refer to Kimi-Audio docs. Trying local path example (update path!). Error: {e}\")\n",
    "    # Fallback example:\n",
    "    # model_path = \"/path/to/your/downloaded/kimia-hf-ckpt\" # IMPORTANT: Update this path if loading locally\n",
    "    # model = KimiAudio(model_path=model_path, load_detokenizer=True)\n",
    "    # model.to(device) # Example device placement\n",
    "\n",
    "# --- 2. Define Sampling Parameters ---\n",
    "sampling_params = {\n",
    "    \"audio_temperature\": 0.8,\n",
    "    \"audio_top_k\": 10,\n",
    "    \"text_temperature\": 0.0,\n",
    "    \"text_top_k\": 5,\n",
    "    \"audio_repetition_penalty\": 1.0,\n",
    "    \"audio_repetition_window_size\": 64,\n",
    "    \"text_repetition_penalty\": 1.0,\n",
    "    \"text_repetition_window_size\": 16,\n",
    "}\n",
    "\n",
    "# --- 3. Example 1: Audio-to-Text (ASR) ---\n",
    "# TODO: Provide actual example audio files or URLs accessible to users\n",
    "# E.g., download sample files first or use URLs\n",
    "# wget https://path/to/your/asr_example.wav -O asr_example.wav\n",
    "# wget https://path/to/your/qa_example.wav -O qa_example.wav\n",
    "asr_audio_path = \"asr_example.wav\" # IMPORTANT: Make sure this file exists\n",
    "qa_audio_path = \"qa_example.wav\" # IMPORTANT: Make sure this file exists\n",
    "\n",
    "messages_asr = [\n",
    "    {\"role\": \"user\", \"message_type\": \"text\", \"content\": \"Please transcribe the following audio:\"},\n",
    "    {\"role\": \"user\", \"message_type\": \"audio\", \"content\": asr_audio_path}\n",
    "]\n",
    "\n",
    "# Generate only text output\n",
    "# Note: Ensure the model object and generate method accept device placement if needed\n",
    "_, text_output = model.generate(messages_asr, **sampling_params, output_type=\"text\")\n",
    "print(\">>> ASR Output Text: \", text_output)\n",
    "# Expected output: \"这并不是告别，这是一个篇章的结束，也是新篇章的开始。\" (Example)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
