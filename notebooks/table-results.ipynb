{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20719151",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "cwd = Path.cwd()\n",
    "if cwd.name == \"notebooks\":\n",
    "    os.chdir(cwd.parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b082c951",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from mllm_emotion_classifier.utils import add_fairness_metrics_to_df\n",
    "from EmoBox.EmoBox import EmoDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca7bd21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "since there is no official valid data, use random split for train valid split, with a ratio of [80, 20]\n",
      "load in 2100 samples, only 2100 exists in data dir EmoBox/data\n",
      "load in 700 samples, only 700 exists in data dir EmoBox/data\n",
      "Num. training samples 2100\n",
      "Num. valid samples 0\n",
      "Num. test samples 700\n",
      "Using label_map {'fear': 'Fear', 'disgust': 'Disgust', 'angry': 'Angry', 'sad': 'Sad', 'ps': 'Surprise', 'neutral': 'Neutral', 'happy': 'Happy'}\n",
      "60 rows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run</th>\n",
       "      <th>dataset</th>\n",
       "      <th>fold</th>\n",
       "      <th>model</th>\n",
       "      <th>prompt</th>\n",
       "      <th>temperature</th>\n",
       "      <th>valid_rate</th>\n",
       "      <th>global_f1_macro</th>\n",
       "      <th>global_f1_weighted</th>\n",
       "      <th>global_accuracy_unweighted</th>\n",
       "      <th>...</th>\n",
       "      <th>language_English_classwise_negative_predictive_value_Neutral</th>\n",
       "      <th>language_English_classwise_negative_predictive_value_Sad</th>\n",
       "      <th>language_English_classwise_negative_predictive_value_Surprise</th>\n",
       "      <th>language_English_classwise_f1_score_Angry</th>\n",
       "      <th>language_English_classwise_f1_score_Disgust</th>\n",
       "      <th>language_English_classwise_f1_score_Fear</th>\n",
       "      <th>language_English_classwise_f1_score_Happy</th>\n",
       "      <th>language_English_classwise_f1_score_Neutral</th>\n",
       "      <th>language_English_classwise_f1_score_Sad</th>\n",
       "      <th>language_English_classwise_f1_score_Surprise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>tess</td>\n",
       "      <td>1</td>\n",
       "      <td>qwen2-audio-instruct</td>\n",
       "      <td>user_labels</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7272</td>\n",
       "      <td>0.7272</td>\n",
       "      <td>0.7671</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8571</td>\n",
       "      <td>0.9979</td>\n",
       "      <td>0.9740</td>\n",
       "      <td>0.9362</td>\n",
       "      <td>0.8291</td>\n",
       "      <td>0.8439</td>\n",
       "      <td>0.9458</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.6226</td>\n",
       "      <td>0.9130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>tess</td>\n",
       "      <td>1</td>\n",
       "      <td>qwen2-audio-instruct</td>\n",
       "      <td>user_labels</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7365</td>\n",
       "      <td>0.7365</td>\n",
       "      <td>0.7600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8671</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9524</td>\n",
       "      <td>0.9515</td>\n",
       "      <td>0.8229</td>\n",
       "      <td>0.8768</td>\n",
       "      <td>0.9360</td>\n",
       "      <td>0.1481</td>\n",
       "      <td>0.5970</td>\n",
       "      <td>0.8235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>tess</td>\n",
       "      <td>1</td>\n",
       "      <td>qwen2-audio-instruct</td>\n",
       "      <td>user_labels</td>\n",
       "      <td>0.7000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7147</td>\n",
       "      <td>0.7147</td>\n",
       "      <td>0.7314</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8759</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9390</td>\n",
       "      <td>0.9278</td>\n",
       "      <td>0.7394</td>\n",
       "      <td>0.7823</td>\n",
       "      <td>0.9215</td>\n",
       "      <td>0.2609</td>\n",
       "      <td>0.6135</td>\n",
       "      <td>0.7578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>tess</td>\n",
       "      <td>1</td>\n",
       "      <td>qwen2-audio-instruct</td>\n",
       "      <td>user_labels</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6301</td>\n",
       "      <td>0.7201</td>\n",
       "      <td>0.7243</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8811</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9724</td>\n",
       "      <td>0.8603</td>\n",
       "      <td>0.7073</td>\n",
       "      <td>0.7627</td>\n",
       "      <td>0.8840</td>\n",
       "      <td>0.3193</td>\n",
       "      <td>0.6098</td>\n",
       "      <td>0.8973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>tess</td>\n",
       "      <td>1</td>\n",
       "      <td>qwen2-audio-instruct</td>\n",
       "      <td>user_labels</td>\n",
       "      <td>1.2000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6024</td>\n",
       "      <td>0.6885</td>\n",
       "      <td>0.6914</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8876</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9419</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6081</td>\n",
       "      <td>0.6824</td>\n",
       "      <td>0.8984</td>\n",
       "      <td>0.3871</td>\n",
       "      <td>0.6042</td>\n",
       "      <td>0.7730</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 327 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   run dataset  fold                 model       prompt  temperature  \\\n",
       "0    0    tess     1  qwen2-audio-instruct  user_labels       0.0001   \n",
       "1    0    tess     1  qwen2-audio-instruct  user_labels       0.3000   \n",
       "2    0    tess     1  qwen2-audio-instruct  user_labels       0.7000   \n",
       "3    0    tess     1  qwen2-audio-instruct  user_labels       1.0000   \n",
       "4    0    tess     1  qwen2-audio-instruct  user_labels       1.2000   \n",
       "\n",
       "   valid_rate  global_f1_macro  global_f1_weighted  \\\n",
       "0         1.0           0.7272              0.7272   \n",
       "1         1.0           0.7365              0.7365   \n",
       "2         1.0           0.7147              0.7147   \n",
       "3         1.0           0.6301              0.7201   \n",
       "4         1.0           0.6024              0.6885   \n",
       "\n",
       "   global_accuracy_unweighted  ...  \\\n",
       "0                      0.7671  ...   \n",
       "1                      0.7600  ...   \n",
       "2                      0.7314  ...   \n",
       "3                      0.7243  ...   \n",
       "4                      0.6914  ...   \n",
       "\n",
       "   language_English_classwise_negative_predictive_value_Neutral  \\\n",
       "0                                             0.8571              \n",
       "1                                             0.8671              \n",
       "2                                             0.8759              \n",
       "3                                             0.8811              \n",
       "4                                             0.8876              \n",
       "\n",
       "   language_English_classwise_negative_predictive_value_Sad  \\\n",
       "0                                             0.9979          \n",
       "1                                             1.0000          \n",
       "2                                             1.0000          \n",
       "3                                             1.0000          \n",
       "4                                             1.0000          \n",
       "\n",
       "   language_English_classwise_negative_predictive_value_Surprise  \\\n",
       "0                                             0.9740               \n",
       "1                                             0.9524               \n",
       "2                                             0.9390               \n",
       "3                                             0.9724               \n",
       "4                                             0.9419               \n",
       "\n",
       "   language_English_classwise_f1_score_Angry  \\\n",
       "0                                     0.9362   \n",
       "1                                     0.9515   \n",
       "2                                     0.9278   \n",
       "3                                     0.8603   \n",
       "4                                     0.8663   \n",
       "\n",
       "   language_English_classwise_f1_score_Disgust  \\\n",
       "0                                       0.8291   \n",
       "1                                       0.8229   \n",
       "2                                       0.7394   \n",
       "3                                       0.7073   \n",
       "4                                       0.6081   \n",
       "\n",
       "   language_English_classwise_f1_score_Fear  \\\n",
       "0                                    0.8439   \n",
       "1                                    0.8768   \n",
       "2                                    0.7823   \n",
       "3                                    0.7627   \n",
       "4                                    0.6824   \n",
       "\n",
       "   language_English_classwise_f1_score_Happy  \\\n",
       "0                                     0.9458   \n",
       "1                                     0.9360   \n",
       "2                                     0.9215   \n",
       "3                                     0.8840   \n",
       "4                                     0.8984   \n",
       "\n",
       "   language_English_classwise_f1_score_Neutral  \\\n",
       "0                                       0.0000   \n",
       "1                                       0.1481   \n",
       "2                                       0.2609   \n",
       "3                                       0.3193   \n",
       "4                                       0.3871   \n",
       "\n",
       "   language_English_classwise_f1_score_Sad  \\\n",
       "0                                   0.6226   \n",
       "1                                   0.5970   \n",
       "2                                   0.6135   \n",
       "3                                   0.6098   \n",
       "4                                   0.6042   \n",
       "\n",
       "   language_English_classwise_f1_score_Surprise  \n",
       "0                                        0.9130  \n",
       "1                                        0.8235  \n",
       "2                                        0.7578  \n",
       "3                                        0.8973  \n",
       "4                                        0.7730  \n",
       "\n",
       "[5 rows x 327 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hparam = 'temperature' # or 'top_p'\n",
    "assert hparam in ['temperature', 'top_p'], \"hparam must be either 'temperature' or 'top_p'\"\n",
    "\n",
    "dataset = 'cremad' # iemocap, meld, cremad, ravdess, emovdb, tess (agegroup only),\n",
    "fold = None # Set to an integer fold number if needed, else None to aggregate all folds\n",
    "sensitive_attr = 'gender' # gender, age, ethnicity, race\n",
    "model = 'qwen2-audio-instruct'\n",
    "\n",
    "metadata_dir = Path('EmoBox/data/')\n",
    "dataset_path = metadata_dir / dataset\n",
    "n_folds = len([d for d in dataset_path.iterdir() if d.is_dir() and d.name.startswith(\"fold_\")])\n",
    "out_dir = Path('outputs') / \"temperature_runs\" if hparam == 'temperature' else Path('outputs') / \"topp_runs\"\n",
    "\n",
    "test = EmoDataset(dataset, './', metadata_dir, fold=1, split=\"test\")\n",
    "emotions = set(test.label_map.values())\n",
    "\n",
    "if fold is None:\n",
    "    dfs = []\n",
    "    for f in range(1, n_folds + 1):\n",
    "        results_csv = out_dir / model / dataset / f'fold_{f}.csv'\n",
    "        df_fold = pd.read_csv(results_csv)\n",
    "        dfs.append(df_fold)\n",
    "    df = pd.concat(dfs, ignore_index=True)\n",
    "else:\n",
    "    results_csv = out_dir / model / dataset / f'fold_{fold}.csv'\n",
    "    df = pd.read_csv(results_csv)\n",
    "\n",
    "print(len(df), \"rows\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6e822d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'key': 'tess-OAF-should-fear',\n",
       " 'audio': array([-2.2856926e-05, -7.4530079e-05, -5.1498064e-05, ...,\n",
       "        -1.9920158e-04, -2.2834234e-04,  0.0000000e+00],\n",
       "       shape=(23805,), dtype=float32),\n",
       " 'label': 'Fear',\n",
       " 'agegroup': '64',\n",
       " 'gender': 'Female',\n",
       " 'language': 'English'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac5c0a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = None\n",
    "df = add_fairness_metrics_to_df(df, emotions, sensitive_attr=sensitive_attr, fairness_name='statistical_parity', run=run)\n",
    "df = add_fairness_metrics_to_df(df, emotions, sensitive_attr=sensitive_attr, fairness_name='equal_opportunity', run=run)\n",
    "df = add_fairness_metrics_to_df(df, emotions, sensitive_attr=sensitive_attr, fairness_name='equal_non_opportunity', run=run)\n",
    "df = add_fairness_metrics_to_df(df, emotions, sensitive_attr=sensitive_attr, fairness_name='predictive_parity', run=run)\n",
    "df = add_fairness_metrics_to_df(df, emotions, sensitive_attr=sensitive_attr, fairness_name='negative_predictive_parity', run=run)\n",
    "df = add_fairness_metrics_to_df(df, emotions, sensitive_attr=sensitive_attr, fairness_name='negative_predictive_parity', run=run)\n",
    "df = add_fairness_metrics_to_df(df, emotions, sensitive_attr=sensitive_attr, fairness_name='overall_accuracy_equality', run=run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "988c7285",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temperature</th>\n",
       "      <th>global_f1_macro</th>\n",
       "      <th>global_accuracy_unweighted</th>\n",
       "      <th>statistical_parity</th>\n",
       "      <th>equal_opportunity</th>\n",
       "      <th>equal_non_opportunity</th>\n",
       "      <th>predictive_parity</th>\n",
       "      <th>negative_predictive_parity</th>\n",
       "      <th>overall_accuracy_equality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>73.88</td>\n",
       "      <td>76.99</td>\n",
       "      <td>1.26</td>\n",
       "      <td>5.80</td>\n",
       "      <td>0.82</td>\n",
       "      <td>5.97</td>\n",
       "      <td>0.93</td>\n",
       "      <td>2.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.3000</td>\n",
       "      <td>72.69</td>\n",
       "      <td>75.52</td>\n",
       "      <td>1.38</td>\n",
       "      <td>6.37</td>\n",
       "      <td>0.81</td>\n",
       "      <td>4.42</td>\n",
       "      <td>0.99</td>\n",
       "      <td>3.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.7000</td>\n",
       "      <td>67.88</td>\n",
       "      <td>74.79</td>\n",
       "      <td>1.42</td>\n",
       "      <td>7.67</td>\n",
       "      <td>1.17</td>\n",
       "      <td>3.82</td>\n",
       "      <td>1.11</td>\n",
       "      <td>2.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>65.96</td>\n",
       "      <td>72.09</td>\n",
       "      <td>1.93</td>\n",
       "      <td>9.08</td>\n",
       "      <td>1.60</td>\n",
       "      <td>4.42</td>\n",
       "      <td>1.29</td>\n",
       "      <td>4.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.2000</td>\n",
       "      <td>61.26</td>\n",
       "      <td>70.79</td>\n",
       "      <td>2.02</td>\n",
       "      <td>10.28</td>\n",
       "      <td>1.93</td>\n",
       "      <td>5.11</td>\n",
       "      <td>1.56</td>\n",
       "      <td>4.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.5000</td>\n",
       "      <td>57.07</td>\n",
       "      <td>65.74</td>\n",
       "      <td>1.85</td>\n",
       "      <td>10.48</td>\n",
       "      <td>2.06</td>\n",
       "      <td>4.82</td>\n",
       "      <td>1.62</td>\n",
       "      <td>3.74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   temperature  global_f1_macro  global_accuracy_unweighted  \\\n",
       "0       0.0001            73.88                       76.99   \n",
       "1       0.3000            72.69                       75.52   \n",
       "2       0.7000            67.88                       74.79   \n",
       "3       1.0000            65.96                       72.09   \n",
       "4       1.2000            61.26                       70.79   \n",
       "5       1.5000            57.07                       65.74   \n",
       "\n",
       "   statistical_parity  equal_opportunity  equal_non_opportunity  \\\n",
       "0                1.26               5.80                   0.82   \n",
       "1                1.38               6.37                   0.81   \n",
       "2                1.42               7.67                   1.17   \n",
       "3                1.93               9.08                   1.60   \n",
       "4                2.02              10.28                   1.93   \n",
       "5                1.85              10.48                   2.06   \n",
       "\n",
       "   predictive_parity  negative_predictive_parity  overall_accuracy_equality  \n",
       "0               5.97                        0.93                       2.51  \n",
       "1               4.42                        0.99                       3.63  \n",
       "2               3.82                        1.11                       2.93  \n",
       "3               4.42                        1.29                       4.96  \n",
       "4               5.11                        1.56                       4.78  \n",
       "5               4.82                        1.62                       3.74  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped = df[[hparam, 'global_f1_macro', 'global_accuracy_unweighted',\n",
    "              'statistical_parity', 'equal_opportunity', 'equal_non_opportunity',\n",
    "              'predictive_parity', 'negative_predictive_parity', 'overall_accuracy_equality']]\n",
    "grouped = grouped.groupby([hparam]).mean().reset_index()\n",
    "\n",
    "for col in grouped.columns:\n",
    "    if col != hparam:\n",
    "        grouped[col] = (grouped[col] * 100).round(2)\n",
    "\n",
    "grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41f4a7f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "temperature                    0.0001\n",
       "global_f1_macro               73.8800\n",
       "global_accuracy_unweighted    76.9900\n",
       "statistical_parity             1.2600\n",
       "equal_opportunity              5.8000\n",
       "equal_non_opportunity          0.8200\n",
       "predictive_parity              5.9700\n",
       "negative_predictive_parity     0.9300\n",
       "overall_accuracy_equality      2.5100\n",
       "Name: 0, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_row = grouped.loc[grouped['global_f1_macro'].idxmax()]\n",
    "best_row"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
