{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a537ddd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "cwd = Path.cwd()\n",
    "if cwd.name == \"notebooks\":\n",
    "    os.chdir(cwd.parent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5886cccb",
   "metadata": {},
   "source": [
    "#### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bef8bdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from EmoBox.EmoBox import EmoDataset, EmoEval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9117126f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "since there is no official valid data, use random split for train valid split, with a ratio of [80, 20]\n",
      "load in 4446 samples, only 4446 exists in data dir EmoBox/data/\n",
      "load in 1085 samples, only 1085 exists in data dir EmoBox/data/\n",
      "Num. training samples 4446\n",
      "Num. valid samples 0\n",
      "Num. test samples 1085\n",
      "Using label_map {'neu': 'Neutral', 'hap': 'Happy', 'ang': 'Angry', 'sad': 'Sad', 'exc': 'Happy'}\n",
      "since there is no official valid data, use random split for train valid split, with a ratio of [80, 20]\n",
      "load in 4446 samples, only 4446 exists in data dir EmoBox/data/\n",
      "load in 1085 samples, only 1085 exists in data dir EmoBox/data/\n",
      "Num. training samples 4446\n",
      "Num. valid samples 0\n",
      "Num. test samples 1085\n",
      "Using label_map {'neu': 'Neutral', 'hap': 'Happy', 'ang': 'Angry', 'sad': 'Sad', 'exc': 'Happy'}\n"
     ]
    }
   ],
   "source": [
    "dataset = \"iemocap\"\n",
    "fold = 1  # different datasets have different number of folds, which can be find in data/\n",
    "user_data_dir = \"./\" # path to EmoBox - FIXED: Changed from \"Emobox\" to \"EmoBox\"\n",
    "meta_data_dir = \"EmoBox/data/\" # path to data folder - FIXED: Changed from \"Emobox\" to \"EmoBox\"\n",
    "label2idx = {'hap':0, 'sad':1, 'ang':2, 'neu':3} # you may need to define a label to index mapping for your own training, see `data/iemocap/label_map.json`\n",
    "\n",
    "train = EmoDataset(dataset, user_data_dir, meta_data_dir, fold=fold, split=\"train\")\n",
    "test = EmoDataset(dataset, user_data_dir, meta_data_dir, fold=fold, split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e3bfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# id = 102\n",
    "# audio_1 = test[id]['audio']\n",
    "# audio_2 = test[id]['audio']\n",
    "# np.array_equal(audio_1, audio_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f2c345f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values(['Neutral', 'Happy', 'Angry', 'Sad', 'Happy'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.label_map.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "361f3a19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'key': 'iemocap-Ses02F_impro07_F001',\n",
       " 'audio': array([ 0.00238037,  0.00213623,  0.00204468, ..., -0.03656006,\n",
       "        -0.03027344, -0.03005981], shape=(36400,), dtype=float32),\n",
       " 'label': 'Happy',\n",
       " 'gender': 'Female',\n",
       " 'language': 'English'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95bb1623",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'Neutral': 384, 'Happy': 278, 'Angry': 229, 'Sad': 194})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "labels =  [data['label'] for data in test]\n",
    "Counter(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ecf386",
   "metadata": {},
   "source": [
    "#### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9589555",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<|audio_bos|><|AUDIO|><|audio_eos|>Classify the speaker’s tone in the audio. Select one of: {'N': 'Neutral', 'H': 'Happy', 'A': 'Angry', 'S': 'Sad'}. Answer:\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AUDIO_PROMPT_TEMPLATE = (\n",
    "    \"<|audio_bos|><|AUDIO|><|audio_eos|>\"\n",
    "    \"Classify the speaker’s tone in the audio. \"\n",
    "    \"Select one of: {labels}. \"\n",
    "    \"Answer:\"\n",
    ")\n",
    "\n",
    "class_labels = test.label_map.values()\n",
    "# letter_to_label = {label[0].upper(): label for label in class_labels}\n",
    "# label_to_letter = {label: label[0].upper() for label in class_labels}\n",
    "# label_options = \", \".join([f\"{label_to_letter[label]}: {label}\" for label in class_labels])\n",
    "label_dict = {label[0]: label for label in class_labels}\n",
    "AUDIO_PROMPT_TEMPLATE = AUDIO_PROMPT_TEMPLATE.format(labels=label_dict)\n",
    "AUDIO_PROMPT_TEMPLATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03cbe8b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/home/dasaro/research/FairMLLM-Emotion-Recognition/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Fetching 5 files: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 60436.66it/s]\n",
      "Loading weights: 100%|█████████████████████████████████████████████████████████████████████████| 876/876 [00:03<00:00, 284.69it/s, Materializing param=multi_modal_projector.linear.weight]\n",
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from mllm_emotion_classifier.models import ModelFactory\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = ModelFactory.create(\n",
    "    name=\"qwen2-audio-instruct\",\n",
    "    # name=\"qwen2-audio\",\n",
    "    # name=\"audio-flamingo-3\",\n",
    "    # checkpoint=\"Qwen/Qwen2-Audio-7B\",\n",
    "    # checkpoint=\"Qwen/Qwen2-Audio-7B-Instruct\",\n",
    "    class_labels=set(test.label_map.values()),\n",
    "    do_sample=True,\n",
    "    device=device,\n",
    "    # prompt_name=\"simple\",\n",
    "    prompt_name=\"user_labels\", # direct, user_labels, cameo\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b459f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = torch.utils.data.DataLoader(\n",
    "    dataset=test,\n",
    "    batch_size=4,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    "    drop_last=False,\n",
    "    collate_fn=model.collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f599406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm import tqdm\n",
    "# import pandas as pd\n",
    "\n",
    "# predictions, labels = [], []\n",
    "# i = 0\n",
    "# for inputs, lbl in tqdm(data_loader, total=len(data_loader)):\n",
    "#     inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "#     preds = model.predict(inputs)\n",
    "#     predictions.extend(preds)\n",
    "#     labels.extend(lbl)\n",
    "#     i += 1\n",
    "    # if len(predictions) >= 300:\n",
    "    #     break\n",
    "\n",
    "# new_data = pd.DataFrame({\n",
    "#     \"label\": labels,\n",
    "#     \"prediction\": predictions,\n",
    "# })\n",
    "# csv_path = \"notebooks/qwen2-audio-iemocap-fold1-predictions-json.csv\"\n",
    "\n",
    "# if os.path.exists(csv_path):\n",
    "#     df = pd.read_csv(csv_path)\n",
    "#     last_digit = df.columns[-1][0]\n",
    "#     next_id = int(last_digit) + 1\n",
    "#     df[f\"{next_id}_prediction\"] = new_data[\"prediction\"]\n",
    "#     print(f\"Added columns with ID {next_id} to existing CSV\")\n",
    "# else:\n",
    "#     df = pd.DataFrame({\n",
    "#         \"label\": new_data[\"label\"],\n",
    "#         \"0_prediction\": new_data[\"prediction\"],\n",
    "#     })\n",
    "#     print(f\"Created new CSV with ID 0\")\n",
    "\n",
    "# df.to_csv(csv_path, index=False)\n",
    "# print(f\"Saved to {csv_path}\")\n",
    "# print(f\"Shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121f4692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from sklearn.metrics import f1_score\n",
    "\n",
    "# csv_path = \"notebooks/qwen2-audio-iemocap-fold1-predictions-subset.csv\"\n",
    "# df = pd.read_csv(csv_path)\n",
    "# prediction_cols = [col for col in df.columns if col.endswith(\"_prediction\")]\n",
    "# y_true = df[\"label\"]\n",
    "\n",
    "# results = []\n",
    "# for pred_col in prediction_cols:\n",
    "#     pred_id = pred_col.split(\"_\")[0]\n",
    "#     y_pred = df[pred_col].dropna()\n",
    "#     y_true_valid = y_true[df[pred_col].notna()]\n",
    "    \n",
    "#     f1_macro = f1_score(y_true_valid, y_pred, average='macro')\n",
    "#     f1_weighted = f1_score(y_true_valid, y_pred, average='weighted')\n",
    "    \n",
    "#     results.append({\n",
    "#         'ID': pred_id,\n",
    "#         'F1 Macro': round(f1_macro, 4),\n",
    "#         'F1 Weighted': round(f1_weighted, 4)\n",
    "#     })\n",
    "\n",
    "# results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9d32b4",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7045a669",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/home/dasaro/research/FairMLLM-Emotion-Recognition/src/mllm_emotion_classifier/evaluate/evaluate.py:87: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  valid_indices = [i for i, p in enumerate(self.y_pred) if p is not \"Unknown\"]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Evaluating qwen2-audio-instruct on iemocap\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference:   0%|                                                                                                                                                   | 0/272 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference:  86%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                  | 235/272 [01:45<00:14,  2.56it/s]Could not confidently parse response: \"Fearful\"\n",
      "Inference: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 272/272 [02:01<00:00,  2.24it/s]\n",
      "/nfs/home/dasaro/research/FairMLLM-Emotion-Recognition/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2801: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/nfs/home/dasaro/research/FairMLLM-Emotion-Recognition/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2801: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/nfs/home/dasaro/research/FairMLLM-Emotion-Recognition/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2801: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'timestamp': '2025-12-16 10:10:10',\n",
       " 'dataset': 'iemocap',\n",
       " 'model_name': 'qwen2-audio-instruct',\n",
       " 'fold': None,\n",
       " 'num_samples': 1085,\n",
       " 'valid_rate': 1.0,\n",
       " 'class_labels': ['Happy', 'Angry', 'Sad', 'Neutral'],\n",
       " 'metrics': {'global': {'f1_macro': 0.5625,\n",
       "   'f1_weighted': 0.6979,\n",
       "   'accuracy_unweighted': 0.712,\n",
       "   'accuracy_weighted': 0.6949,\n",
       "   'precision_macro': 0.5699,\n",
       "   'precision_weighted': 0.7161,\n",
       "   'recall_macro': 0.5696,\n",
       "   'recall_weighted': 0.6949},\n",
       "  'classwise': {'accuracy': {'Angry': 0.9336,\n",
       "    'Happy': 0.8618,\n",
       "    'Neutral': 0.7594,\n",
       "    'Sad': 0.8359},\n",
       "   'false_positive_rate': {'Angry': 0.0397,\n",
       "    'Happy': 0.0508,\n",
       "    'Neutral': 0.174,\n",
       "    'Sad': 0.1493},\n",
       "   'false_negative_rate': {'Angry': 0.1659,\n",
       "    'Happy': 0.3921,\n",
       "    'Neutral': 0.362,\n",
       "    'Sad': 0.232},\n",
       "   'true_positive_rate': {'Angry': 0.8341,\n",
       "    'Happy': 0.6079,\n",
       "    'Neutral': 0.638,\n",
       "    'Sad': 0.768},\n",
       "   'true_negative_rate': {'Angry': 0.9603,\n",
       "    'Happy': 0.9492,\n",
       "    'Neutral': 0.826,\n",
       "    'Sad': 0.8507},\n",
       "   'positive_predictive_value': {'Angry': 0.8489,\n",
       "    'Happy': 0.8048,\n",
       "    'Neutral': 0.6676,\n",
       "    'Sad': 0.5284},\n",
       "   'negative_predictive_value': {'Angry': 0.9558,\n",
       "    'Happy': 0.8754,\n",
       "    'Neutral': 0.8064,\n",
       "    'Sad': 0.944},\n",
       "   'f1_score': {'Angry': 0.8414,\n",
       "    'Happy': 0.6926,\n",
       "    'Neutral': 0.6525,\n",
       "    'Sad': 0.6261}},\n",
       "  'gender': {'Female': {'global': {'f1_macro': 0.6904,\n",
       "     'f1_weighted': 0.7016,\n",
       "     'accuracy_unweighted': 0.712,\n",
       "     'accuracy_weighted': 0.697,\n",
       "     'precision_macro': 0.699,\n",
       "     'precision_weighted': 0.7288,\n",
       "     'recall_macro': 0.712,\n",
       "     'recall_weighted': 0.697},\n",
       "    'classwise': {'accuracy': {'Angry': 0.9167,\n",
       "      'Happy': 0.8845,\n",
       "      'Neutral': 0.7708,\n",
       "      'Sad': 0.822},\n",
       "     'false_positive_rate': {'Angry': 0.0604,\n",
       "      'Happy': 0.0505,\n",
       "      'Neutral': 0.1148,\n",
       "      'Sad': 0.1689},\n",
       "     'false_negative_rate': {'Angry': 0.1429,\n",
       "      'Happy': 0.3106,\n",
       "      'Neutral': 0.4678,\n",
       "      'Sad': 0.2308},\n",
       "     'true_positive_rate': {'Angry': 0.8571,\n",
       "      'Happy': 0.6894,\n",
       "      'Neutral': 0.5322,\n",
       "      'Sad': 0.7692},\n",
       "     'true_negative_rate': {'Angry': 0.9396,\n",
       "      'Happy': 0.9495,\n",
       "      'Neutral': 0.8852,\n",
       "      'Sad': 0.8311},\n",
       "     'positive_predictive_value': {'Angry': 0.8456,\n",
       "      'Happy': 0.8198,\n",
       "      'Neutral': 0.6894,\n",
       "      'Sad': 0.4412},\n",
       "     'negative_predictive_value': {'Angry': 0.9446,\n",
       "      'Happy': 0.9017,\n",
       "      'Neutral': 0.798,\n",
       "      'Sad': 0.9541},\n",
       "     'f1_score': {'Angry': 0.8514,\n",
       "      'Happy': 0.749,\n",
       "      'Neutral': 0.6007,\n",
       "      'Sad': 0.5607}}},\n",
       "   'Male': {'global': {'f1_macro': 0.5653,\n",
       "     'f1_weighted': 0.6924,\n",
       "     'accuracy_unweighted': 0.7043,\n",
       "     'accuracy_weighted': 0.693,\n",
       "     'precision_macro': 0.5816,\n",
       "     'precision_weighted': 0.71,\n",
       "     'recall_macro': 0.5634,\n",
       "     'recall_weighted': 0.693},\n",
       "    'classwise': {'accuracy': {'Angry': 0.9497,\n",
       "      'Happy': 0.8402,\n",
       "      'Neutral': 0.7487,\n",
       "      'Sad': 0.8492},\n",
       "     'false_positive_rate': {'Angry': 0.0232,\n",
       "      'Happy': 0.0511,\n",
       "      'Neutral': 0.2355,\n",
       "      'Sad': 0.1293},\n",
       "     'false_negative_rate': {'Angry': 0.2073,\n",
       "      'Happy': 0.4658,\n",
       "      'Neutral': 0.277,\n",
       "      'Sad': 0.2328},\n",
       "     'true_positive_rate': {'Angry': 0.7927,\n",
       "      'Happy': 0.5342,\n",
       "      'Neutral': 0.723,\n",
       "      'Sad': 0.7672},\n",
       "     'true_negative_rate': {'Angry': 0.9768,\n",
       "      'Happy': 0.9489,\n",
       "      'Neutral': 0.7645,\n",
       "      'Sad': 0.8707},\n",
       "     'positive_predictive_value': {'Angry': 0.8553,\n",
       "      'Happy': 0.7879,\n",
       "      'Neutral': 0.6553,\n",
       "      'Sad': 0.6096},\n",
       "     'negative_predictive_value': {'Angry': 0.9647,\n",
       "      'Happy': 0.8515,\n",
       "      'Neutral': 0.8168,\n",
       "      'Sad': 0.9343},\n",
       "     'f1_score': {'Angry': 0.8228,\n",
       "      'Happy': 0.6367,\n",
       "      'Neutral': 0.6875,\n",
       "      'Sad': 0.6794}}}},\n",
       "  'language': {'English': {'global': {'f1_macro': 0.5625,\n",
       "     'f1_weighted': 0.6979,\n",
       "     'accuracy_unweighted': 0.712,\n",
       "     'accuracy_weighted': 0.6949,\n",
       "     'precision_macro': 0.5699,\n",
       "     'precision_weighted': 0.7161,\n",
       "     'recall_macro': 0.5696,\n",
       "     'recall_weighted': 0.6949},\n",
       "    'classwise': {'accuracy': {'Angry': 0.9336,\n",
       "      'Happy': 0.8618,\n",
       "      'Neutral': 0.7594,\n",
       "      'Sad': 0.8359},\n",
       "     'false_positive_rate': {'Angry': 0.0397,\n",
       "      'Happy': 0.0508,\n",
       "      'Neutral': 0.174,\n",
       "      'Sad': 0.1493},\n",
       "     'false_negative_rate': {'Angry': 0.1659,\n",
       "      'Happy': 0.3921,\n",
       "      'Neutral': 0.362,\n",
       "      'Sad': 0.232},\n",
       "     'true_positive_rate': {'Angry': 0.8341,\n",
       "      'Happy': 0.6079,\n",
       "      'Neutral': 0.638,\n",
       "      'Sad': 0.768},\n",
       "     'true_negative_rate': {'Angry': 0.9603,\n",
       "      'Happy': 0.9492,\n",
       "      'Neutral': 0.826,\n",
       "      'Sad': 0.8507},\n",
       "     'positive_predictive_value': {'Angry': 0.8489,\n",
       "      'Happy': 0.8048,\n",
       "      'Neutral': 0.6676,\n",
       "      'Sad': 0.5284},\n",
       "     'negative_predictive_value': {'Angry': 0.9558,\n",
       "      'Happy': 0.8754,\n",
       "      'Neutral': 0.8064,\n",
       "      'Sad': 0.944},\n",
       "     'f1_score': {'Angry': 0.8414,\n",
       "      'Happy': 0.6926,\n",
       "      'Neutral': 0.6525,\n",
       "      'Sad': 0.6261}}}}}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mllm_emotion_classifier.evaluate import Evaluator\n",
    "\n",
    "evaluator = Evaluator()\n",
    "evaluator.evaluate(model, data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "840f8093",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f1_macro': 0.5625,\n",
       " 'f1_weighted': 0.6979,\n",
       " 'accuracy_unweighted': 0.712,\n",
       " 'accuracy_weighted': 0.6949,\n",
       " 'precision_macro': 0.5699,\n",
       " 'precision_weighted': 0.7161,\n",
       " 'recall_macro': 0.5696,\n",
       " 'recall_weighted': 0.6949}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.results['metrics']['global']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315293a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'global_f1_macro': 0.2274,\n",
       " 'global_f1_weighted': 0.2685,\n",
       " 'global_accuracy_unweighted': 0.3222,\n",
       " 'global_accuracy_weighted': 0.3173,\n",
       " 'global_precision_macro': 0.3274,\n",
       " 'global_precision_weighted': 0.4028,\n",
       " 'global_recall_macro': 0.2819,\n",
       " 'global_recall_weighted': 0.3173,\n",
       " 'classwise_accuracy_Angry': 0.8462,\n",
       " 'classwise_accuracy_Disgust': 0.9327,\n",
       " 'classwise_accuracy_Fear': 0.8846,\n",
       " 'classwise_accuracy_Happy': 0.875,\n",
       " 'classwise_accuracy_Neutral': 0.8558,\n",
       " 'classwise_accuracy_Sad': 0.4038,\n",
       " 'classwise_accuracy_Surprise': 0.8558,\n",
       " 'classwise_false_positive_rate_Angry': 0.0,\n",
       " 'classwise_false_positive_rate_Disgust': 0.0114,\n",
       " 'classwise_false_positive_rate_Fear': 0.0,\n",
       " 'classwise_false_positive_rate_Happy': 0.0899,\n",
       " 'classwise_false_positive_rate_Neutral': 0.0,\n",
       " 'classwise_false_positive_rate_Sad': 0.6593,\n",
       " 'classwise_false_positive_rate_Surprise': 0.0,\n",
       " 'classwise_false_negative_rate_Angry': 1.0,\n",
       " 'classwise_false_negative_rate_Disgust': 0.375,\n",
       " 'classwise_false_negative_rate_Fear': 1.0,\n",
       " 'classwise_false_negative_rate_Happy': 0.3333,\n",
       " 'classwise_false_negative_rate_Neutral': 0.8824,\n",
       " 'classwise_false_negative_rate_Sad': 0.1538,\n",
       " 'classwise_false_negative_rate_Surprise': 1.0,\n",
       " 'classwise_true_positive_rate_Angry': 0.0,\n",
       " 'classwise_true_positive_rate_Disgust': 0.625,\n",
       " 'classwise_true_positive_rate_Fear': 0.0,\n",
       " 'classwise_true_positive_rate_Happy': 0.6667,\n",
       " 'classwise_true_positive_rate_Neutral': 0.1176,\n",
       " 'classwise_true_positive_rate_Sad': 0.8462,\n",
       " 'classwise_true_positive_rate_Surprise': 0.0,\n",
       " 'classwise_true_negative_rate_Angry': 1.0,\n",
       " 'classwise_true_negative_rate_Disgust': 0.9886,\n",
       " 'classwise_true_negative_rate_Fear': 1.0,\n",
       " 'classwise_true_negative_rate_Happy': 0.9101,\n",
       " 'classwise_true_negative_rate_Neutral': 1.0,\n",
       " 'classwise_true_negative_rate_Sad': 0.3407,\n",
       " 'classwise_true_negative_rate_Surprise': 1.0,\n",
       " 'classwise_positive_predictive_value_Angry': 0.0,\n",
       " 'classwise_positive_predictive_value_Disgust': 0.9091,\n",
       " 'classwise_positive_predictive_value_Fear': 0.0,\n",
       " 'classwise_positive_predictive_value_Happy': 0.5556,\n",
       " 'classwise_positive_predictive_value_Neutral': 1.0,\n",
       " 'classwise_positive_predictive_value_Sad': 0.1549,\n",
       " 'classwise_positive_predictive_value_Surprise': 0.0,\n",
       " 'classwise_negative_predictive_value_Angry': 0.8462,\n",
       " 'classwise_negative_predictive_value_Disgust': 0.9355,\n",
       " 'classwise_negative_predictive_value_Fear': 0.8846,\n",
       " 'classwise_negative_predictive_value_Happy': 0.9419,\n",
       " 'classwise_negative_predictive_value_Neutral': 0.8529,\n",
       " 'classwise_negative_predictive_value_Sad': 0.9394,\n",
       " 'classwise_negative_predictive_value_Surprise': 0.8558,\n",
       " 'classwise_f1_score_Angry': 0.0,\n",
       " 'classwise_f1_score_Disgust': 0.7407,\n",
       " 'classwise_f1_score_Fear': 0.0,\n",
       " 'classwise_f1_score_Happy': 0.6061,\n",
       " 'classwise_f1_score_Neutral': 0.2105,\n",
       " 'classwise_f1_score_Sad': 0.2619,\n",
       " 'classwise_f1_score_Surprise': 0.0}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mllm_emotion_classifier.utils import flatten_dict\n",
    "metrics = flatten_dict(evaluator.results['metrics'])\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e4f66c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': {'Angry': 0.86, 'Happy': 0.86, 'Neutral': 0.73, 'Sad': 0.73},\n",
       " 'false_positive_rate': {'Angry': 0.0,\n",
       "  'Happy': 0.1443,\n",
       "  'Neutral': 0.0,\n",
       "  'Sad': 0.3103},\n",
       " 'false_negative_rate': {'Angry': 0.3684,\n",
       "  'Happy': 0.0,\n",
       "  'Neutral': 0.587,\n",
       "  'Sad': 0.0},\n",
       " 'true_positive_rate': {'Angry': 0.6316,\n",
       "  'Happy': 1.0,\n",
       "  'Neutral': 0.413,\n",
       "  'Sad': 1.0},\n",
       " 'true_negative_rate': {'Angry': 1.0,\n",
       "  'Happy': 0.8557,\n",
       "  'Neutral': 1.0,\n",
       "  'Sad': 0.6897},\n",
       " 'positive_predictive_value': {'Angry': 1.0,\n",
       "  'Happy': 0.1765,\n",
       "  'Neutral': 1.0,\n",
       "  'Sad': 0.325},\n",
       " 'negative_predictive_value': {'Angry': 0.8158,\n",
       "  'Happy': 1.0,\n",
       "  'Neutral': 0.6667,\n",
       "  'Sad': 1.0},\n",
       " 'f1_score': {'Angry': 0.7742, 'Happy': 0.3, 'Neutral': 0.5846, 'Sad': 0.4906}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.results['metrics']['classwise']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
